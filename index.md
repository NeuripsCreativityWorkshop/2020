## Introduction

Generative machine learning and machine creativity have continued to grow and attract a wider audience to machine learning. Generative models enable new types of media creation across images, music, and text - including recent advances such as StyleGAN2, Jukebox and GPT-3. This one-day workshop broadly explores issues in the applications of machine learning to creativity and design. We will look at algorithms for generation and creation of new media, engaging researchers building the next generation of generative models (GANs, RL, etc). We investigate the social and cultural impact of these new models, engaging researchers from HCI/UX communities and those using machine learning to develop new creative tools. In addition to covering the technical advances, we also address the ethical concerns ranging from the use of biased datasets to replicating artistic work. Finally, we’ll hear from some of the artists and musicians who are adopting machine learning including deep learning and reinforcement learning as part of their own artistic process.  We aim to balance the technical issues and challenges of applying the latest generative models to creativity and design with philosophical and cultural issues that surround this area of research.

The goal of this workshop is to bring together researchers interested in advancing art and music generation to present new work, foster collaborations and build networks with the aim of solving the most pressing problems in the field.

## How To Participate

We invite participation in the form of papers and/or artwork.

### To Submit a Paper

We invite participants to submit 2-page papers in the NeurIPS [camera-ready format](https://nips.cc/Conferences/2020/PaperInformation/StyleFiles) (with author names visible), to be submitted to: `neurips2020creativity@gmail.com`

In the subject line of your email, please put:

```
NeurIPS Workshop: [Paper title]
```

Topics may include (but are not limited to):

* Presentation of new machine learning techniques for generating art, music, or other creative outputs using, for instance, reinforcement learning, generative adversarial networks, novelty search and evaluation, etc
* Quantitative or qualitative evaluation of machine learning techniques for creative work and design
* Tools or techniques to improve usability or usefulness of machine learning for creative practitioners
* Descriptions, reflections, or case studies on the use of machine learning in the creation of a new art or design work
* Information-theoretic views of creativity
* Aesthetic, philosophical, social, cultural and ethical considerations surrounding the use of machine learning in creative practice

We encourage all authors to consider the ethical implications of their work. This can be discussed in a 1-paragraph section at the end of the paper and will not count towards the page limit.

In your submission, you may also indicate whether you would like to present a demo of your work during the workshop (if applicable).

Papers will be reviewed by committee members, and accepted authors will present at the workshop in the form of a short talk, panel, and/or demo. At least one author of each accepted paper must register for and attend the workshop. Accepted papers will appear on the workshop website. Please note that we do not adhere to a formal peer review process and are normally unable to provide detailed feedback on individual submissions. 

References and any supplementary materials provided do not count as part of the 2-page limit. However, it will be the reviewers’ discretion to read the supplementary materials.

### To Submit Artwork

We welcome submission of artwork that has been created using machine learning (autonomously or with humans). We invite art submissions in any medium, including but not limited to:

* Image
* Video
* Music
* Writing
* Sound
* Dance, Performance, Installation, Physical Object, Food, etc 

We can accommodate work submitted in one of the following formats: video, audio (maximum 2 channel), still image or website. Other types of submissions (e.g., physical artefacts, performances, text, …) should be documented using one or more of the above formats. For instance, you might submit a video of a machine-learning-generated dance piece or a website documenting a text generation piece.

We will display the accepted art submissions on the [workshop gallery](http://www.aiartonline.com/) and will do our best to show a number of art pieces at the online workshop itself. We may invite creators of accepted artwork to participate in the form of a short talk, panel, and/or demo.

On this submission [page](https://docs.google.com/forms/d/e/1FAIpQLSd2SZvAtujcnOLmFvYQUN0qo5plCFi9dblwMabWc0_WibijEQ/viewform), you will also be asked for a short text description of your work and a description of how machine learning was used in its creation. 

## Invited Speakers

Coming soon!

<!-- TODO: add links to personal pages -->

## Important Dates

9 October 2020: Submission date for papers and art

30 October 2020: Acceptance notification for papers and art

6–12 December 2020: NeurIPS Conference

11 or 12 December 2020 (TBA): Workshop

## Contact

If you have any questions, please contact us at `neurips2020creativity@gmail.com`

Workshop website: [https://neurips2020creativity.github.io](https://neurips2020creativity.github.io)

Previous years:

* [2019 workshop](http://neurips2019creativity.github.io/) (Vancouver, Canada)
* [2018 workshop](https://nips2018creativity.github.io/) (Montreal, Canada)
* [2017 workshop](https://nips2017creativity.github.io/) (Long Beach, CA, USA)

The art submissions from previous years can be viewed [here](http://www.aiartonline.com/)

## Organisers

[Luba Elliott](https://twitter.com/elluba), AI Curator

[Sander Dieleman](https://twitter.com/sedielem), DeepMind

[Adam Roberts](https://twitter.com/ada_rob),  Magenta, Google Brain

[Tom White](https://twitter.com/dribnet), Victoria University of Wellington

[Holly Grimm](https://twitter.com/hollygrimm), Artist and freelance creative technologist

[Mattie Tesfaldet](https://twitter.com/mtesfald), McGill University / MILA

[Samaneh Azadi](https://twitter.com/smnh_azadi), UC Berkeley

[Daphne Ippolito](https://twitter.com/daphneipp), University of Pennsylvania / Google Brain
